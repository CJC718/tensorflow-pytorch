# tensorflow-pytorch
## 第一个项目 ##

提出了基于词袋模型的数据集分类解决方案，该方案是通过建立视觉词典对数据进行分类。
Bag-of-words模型是信息检索领域常用的文档表示方法。但是这里我们将Bag-of-words模型应用于图像表示。我们将图像看作文档，即若干个“视觉词汇”的集合。由于图像中的词汇不像文本中的那样是现成的，我们需要首先从图像中提取出相互独立的视觉词汇，这通常由三步组成。第一步，利用Hog算法提取图像的特征。第二步，使用Kmeans聚类算法将提取出的特征聚成k个簇，簇类特征具有高度相似性，这k个簇类的中心就是k个视觉词汇，这些视觉词汇构成视觉词典。第三步，利用视觉词典的中词汇表示图像。通过统计单词表中每个单词在图像中出现的次数，可以将图像表示成为一个K维数值向量。最后将测试集形成的频率直方图与训练集形成的频率直方图使用 KNN 进 直方图匹配，得到测试结果

## 第二个项目 ##

目的就是使用yolov5模型实现对到道路区域的物体的检测。首先，我进行了一些调研，因为yolov系列对设备比较友好，所以我就选取了yolov5来作为网络模型。然后我训练集选用coco数据集的特定数据类别的部分数据，比如car，person，bus等。这些在实际区域中经常出现。然后我使用make sense，手动标记了一些图片添加进数据集。第一次实验，我没有使用已经预训练好的网络，从头开始训练，训练大概四五个小时，训练结果很差，测试很多图片没有检测框。由于设备限制，我就选取一个已经训练好的最轻量化的网络yolo5s来训练，然后调整image-weights，multi-scale，label-smoothing，使得训练的模 型更加准确，泛化性更强。训练结束后，选取合适的目标检测阈值以及 IOU 阈值，得到最终预测结果。
结果:在经过三个多小时训练，300 次迭代之后，对行人检测置信度达到 85%以上，对广告牌以及标志牌的 置信度达到 60%，对手机等小物体置信度达到 20%。

## YoloV5 ##

 ![image](https://user-images.githubusercontent.com/68943201/139177628-bf36e9aa-3c04-4c8a-8f11-7b2b84fbff6c.png)


